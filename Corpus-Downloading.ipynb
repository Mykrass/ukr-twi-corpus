{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running following cell, please create file users.py and create a list with Twitter user nicknames in this file, e.g.: \n",
    "\n",
    "users = ['aaa', 'bbb', 'ccc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import twitter_scraper\n",
    "from twitter_scraper import get_tweets_search\n",
    "import pandas as pd\n",
    "import csv\n",
    "import xml\n",
    "from lxml.etree import ParserError\n",
    "import os, path, sys\n",
    "import glob\n",
    "\n",
    "import re\n",
    "import matplotlib.dates\n",
    "import matplotlib\n",
    "import matplotlib.pyplot\n",
    "import datetime\n",
    "import users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_cache = dict() # twitter_scraper.load_url_cache(\"/tmp/web-cache_compact.dat\")\n",
    "last_request_time = katya_twitter_scraper.Bag(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for user in users:\n",
    "    pages = 4500 # 20 tweets per page\n",
    "    l = []\n",
    "    for tweet in get_tweets_search(user, url_cache, last_request_time, pages):\n",
    "        l.append(tweet)\n",
    "    print(\"Downloaded {} tweets for user {}\".format(len(l), user))\n",
    "    print(datetime.datetime.now())\n",
    "    df = pd.DataFrame(l, columns = tweet.keys())\n",
    "    df.to_csv('users/{}.csv'.format(user))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_scraper.save_url_cache(url_cache, \"/tmp/web-cache_compact.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path ='users//' \n",
    "allFiles = glob.glob(path + \"/*.csv\")\n",
    "\n",
    "list_ = []\n",
    "\n",
    "for file_ in allFiles:\n",
    "    df = pd.read_csv(file_,index_col=None, header=0,\n",
    "                 lineterminator='\\n')\n",
    "    list_.append(df)\n",
    "\n",
    "df = pd.concat(list_, axis = 0, ignore_index = True)\n",
    "\n",
    "df = df.loc[:, ~df.columns.str.contains('^Unnamed')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1829451"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('users/df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('users/df.csv', index_col=0, header=0,\n",
    "                 lineterminator='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def twi_replace(text):\n",
    "    if 'pic.twitter' in text:\n",
    "        new = re.sub('pic.twitter.com/[\\w]+', ' urlTag ', text)\n",
    "        return new\n",
    "    else:\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twi_replace('Ось тримай пательню, щоб жар не псувати. Вьо нахт кухен, як пропонує попередній оратор.pic.twitter.com/30xKIH2FlY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pynlple.processing.preprocessor import *\n",
    "\n",
    "stack = [\n",
    "                                        HtmlEntitiesUnescaper(),\n",
    "                                        BoldTagReplacer(),\n",
    "                                        URLReplacer(' urlTag '),\n",
    "                                        HtmlTagReplacer(' '),\n",
    "                                        EmailReplacer(' emailTag '),\n",
    "                                        PhoneNumberReplacer(' phoneNumberTag '),\n",
    "                                        AtReferenceReplacer(' atRefTag '),\n",
    "                                        CommaReplacer(),\n",
    "                                        QuotesReplacer(),\n",
    "                                        DoubleQuotesReplacer(),\n",
    "                                        SoftHyphenReplacer(),\n",
    "                                        DashAndMinusReplacer(),\n",
    "                                        TripledotReplacer(),\n",
    "                                        ToLowerer(),\n",
    "                                        DigitsReplacer(True, '0'),\n",
    "                                        MultiPunctuationReplacer(),\n",
    "                                        MultiNewLineReplacer(),\n",
    "                                        MultiWhitespaceReplacer(),\n",
    "                                        WordTokenizer(),\n",
    "                                        Trimmer(),\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "t = StackingPreprocessor(stack)\n",
    "df['preproc_text'] = df[\"text\"].apply(lambda x: t.preprocess(twi_replace(str(x)))).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Language Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycld2 as cld2\n",
    "%time\n",
    "df['cld2'] = [cld2.detect(str(i))[2][0][1] for i in df['preproc_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyfasttext import FastText\n",
    "model = FastText('models/lid.176.bin') \n",
    "df['ft'] = [model.predict_proba([str(i)], 1)[0][0][0] for i in df['preproc_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('cld2').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('ft').count()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
